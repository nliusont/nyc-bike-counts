{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook totals the bike counts for the most predominant bike counters then pulls in weather data to be used as input features for modelling.\n",
    "There two weather sources for data, though it could all be retrieved from Open Mateo (which was discovered later in the project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# utils\n",
    "from datetime import datetime, date, timedelta\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# NOAA\n",
    "import requests\n",
    "import json\n",
    "\n",
    "Token='' #### removed\n",
    "today = date.today().strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import bike data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull biking data\n",
    "data = pd.read_pickle('data/all_data.pkl')\n",
    "\n",
    "# limit data to the below counters and after 2013\n",
    "counters = ['Manhattan Br', 'Brooklyn Br', 'Williamsburg Br', 'Kent Ave', 'Queensboro Br', 'Prospect Park W']\n",
    "data = data[data['name'].isin(counters)].copy()\n",
    "data = data[data['date'].dt.year > 2013]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import weather data from NOAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on TAVG,TMAX\n",
      "working on TMIN,PRCP\n",
      "working on AWND,SNOW\n",
      "working on SNWD,TSUN\n"
     ]
    }
   ],
   "source": [
    "# set params\n",
    "dataset = 'GHCND'\n",
    "station_id = 'GHCND:USW00014732' # LGA\n",
    "data_types = ['TAVG', 'TMAX', 'TMIN', 'PRCP', 'AWND', 'SNOW', 'SNWD']\n",
    "\n",
    "start_year = 2014\n",
    "end_year = data['date'].dt.year.max()+1\n",
    "\n",
    "results = []\n",
    "\n",
    "# NOAA limits responses to the first 1,000 hence they must be performed year- and data_type-wise\n",
    "for i in range(0, len(data_types) - 1, 2):\n",
    "    types = data_types[i:i+2]\n",
    "    data_request = ','.join(types)\n",
    "    dt_results = []\n",
    "\n",
    "    print('working on '+data_request)\n",
    "\n",
    "    for year in range(start_year, end_year):\n",
    "        year = str(year)\n",
    "\n",
    "        # temps\n",
    "        # make the api call\n",
    "        r = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid='+dataset+'&limit=1000&stationid='+station_id+'&datatypeid='+data_request+'&startdate='+year+'-01-01&enddate='+year+'-12-31&units=standard', headers={'token':Token})\n",
    "        time.sleep(0.1)\n",
    "        # load the api response as a json\n",
    "        d = json.loads(r.text)\n",
    "        results += d['results']\n",
    "\n",
    "if len(data_types) % 2 == 1: # pairwise looping will miss the last element if it has an odd number\n",
    "    data_request = data_types[-1]\n",
    "    print('working on '+data_request)\n",
    "\n",
    "    for year in range(start_year, end_year):\n",
    "        year = str(year)\n",
    "\n",
    "        # temps\n",
    "        # make the api call\n",
    "        r = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid='+dataset+'&limit=1000&stationid='+station_id+'&datatypeid='+data_request+'&startdate='+year+'-01-01&enddate='+year+'-12-31&units=standard', headers={'token':Token})\n",
    "        time.sleep(0.1)\n",
    "        # load the api response as a json\n",
    "        d = json.loads(r.text)\n",
    "        results += d['results']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "with open('data/raw_wthr.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4p/cnm8c74x2cscn3bny0pr_bvr0000gn/T/ipykernel_64447/1614262759.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  wthr = pd.concat([wthr, dt_df])\n",
      "/var/folders/4p/cnm8c74x2cscn3bny0pr_bvr0000gn/T/ipykernel_64447/1614262759.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  wthr = pd.concat([wthr, dt_df])\n"
     ]
    }
   ],
   "source": [
    "# get data types we want\n",
    "wthr = pd.DataFrame(columns=['date', 'param', 'value'])\n",
    "\n",
    "for dt in data_types:\n",
    "    dt_data = [[x['date'], x['datatype'], x['value']] for x in results if x['datatype']==dt]\n",
    "    dt_df = pd.DataFrame(dt_data, columns=['date', 'param', 'value'])\n",
    "    wthr = pd.concat([wthr, dt_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dupes then pivot so each data type has its own column\n",
    "wthr = wthr.drop_duplicates()\\\n",
    "        .pivot(index='date', columns=['param'], values=['value']).reset_index()\\\n",
    "        .dropna()\n",
    "wthr['date'] = pd.to_datetime(wthr['date'])\n",
    "wthr.columns = ['date', 'AWND', 'PRCP', 'SNOW', 'SNWD', 'TAVG', 'TMAX', 'TMIN']\n",
    "wthr.columns = [x.lower() for x in wthr.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pull weather data from Open Mateo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discovered this other source with hourly data for many features\n",
    "# requests are simple, no api key needed\n",
    "url = f'https://archive-api.open-meteo.com/v1/archive?latitude=40.776&longitude=-73.8727&start_date={start_year}-01-01&end_date={today}&hourly=temperature_2m,dewpoint_2m,cloudcover_low,is_day,direct_radiation,precipitation,apparent_temperature,windspeed_10m&timezone=America%2FNew_York&temperature_unit=fahrenheit&precipitation_unit=inch&windspeed_unit=mph'\n",
    "r = requests.get(url)\n",
    "d = json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "with open('data/raw_wthr_2.pkl', 'wb') as f:\n",
    "    pickle.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse json to retrieve data and make df\n",
    "wthr2 = pd.DataFrame({\n",
    "    'date':d['hourly']['time'],\n",
    "    'dew':d['hourly']['dewpoint_2m'],\n",
    "    'is_day':d['hourly']['is_day'],\n",
    "    'rad':d['hourly']['direct_radiation'],\n",
    "    'precip':d['hourly']['precipitation'],\n",
    "    'temp':d['hourly']['temperature_2m'],\n",
    "    'real_feel':d['hourly']['apparent_temperature'],\n",
    "    'wind':d['hourly']['windspeed_10m']\n",
    "}).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create daytime features by masking with is_day\n",
    "wthr2['day_tmin'] = wthr2['is_day'] * wthr2['temp']\n",
    "wthr2['day_precip'] = wthr2['is_day'] * wthr2['precip']\n",
    "wthr2['day_real_feel'] = wthr2['is_day'] * wthr2['real_feel']\n",
    "wthr2['day_dew'] = wthr2['is_day'] * wthr2['dew']\n",
    "wthr2['day_wind'] = wthr2['is_day'] * wthr2['wind']\n",
    "\n",
    "#day dew and day real feel will average zeroes unless you fill with na\n",
    "wthr2.loc[wthr2['is_day']==0., 'day_dew'] = np.nan\n",
    "wthr2.loc[wthr2['is_day']==0., 'day_real_feel'] = np.nan\n",
    "wthr2.loc[wthr2['is_day']==0., 'day_wind'] = np.nan\n",
    "\n",
    "wthr2['date'] = pd.to_datetime(wthr2['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by the date\n",
    "wthr2 = wthr2.groupby(wthr2['date'].dt.date).agg({\n",
    "    'dew':'mean',\n",
    "    'is_day':'sum',\n",
    "    'rad':'sum',\n",
    "    'precip':'sum',\n",
    "    'day_tmin':'min',\n",
    "    'day_dew':'mean',\n",
    "    'day_precip':'sum',\n",
    "    'real_feel':'mean',\n",
    "    'day_real_feel':'mean',\n",
    "    'wind':'mean',\n",
    "    'day_wind':'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "wthr2['date'] = pd.to_datetime(wthr2['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge two weather datasets to count df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge new OM data with NOAA data\n",
    "wthr = wthr.merge(wthr2, how='left', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by date\n",
    "df = data[['date', 'counts']]\\\n",
    "        .groupby([pd.Grouper(key='date', freq='D')])\\\n",
    "        .sum()\\\n",
    "        .reset_index()\n",
    "\n",
    "df = df.merge(wthr, on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "df.to_pickle('data/by_day_weather.pkl')\n",
    "wthr.to_pickle('data/weather_data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
